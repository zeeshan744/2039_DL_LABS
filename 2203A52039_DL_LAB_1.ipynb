{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1) Write python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with outcome of libraries\n",
        "\n",
        "YActual YP red\n",
        "20 20.5\n",
        "30 30.3\n",
        "40 40.2\n",
        "50 50.6\n",
        "60 60.7\n",
        "Tabela 1: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "xEuYHl2uJPxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual = [20, 30, 40, 50, 60]\n",
        "y_pred = [20.5, 30.3, 40.2, 50.6, 60.7]\n",
        "\n",
        "n = len(y_actual)\n",
        "mae = sum(abs(ya - yp) for ya, yp in zip(y_actual, y_pred)) / n\n",
        "mse = sum((ya - yp) ** 2 for ya, yp in zip(y_actual, y_pred)) / n\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On6OGzrmJS-K",
        "outputId": "92461ea2-0743-47ad-8208-94b05544d2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With libraries."
      ],
      "metadata": {
        "id": "l2__D0XvJeZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_actual = np.array([20, 30, 40, 50, 60])\n",
        "y_pred = np.array([20.5, 30.3, 40.2, 50.6, 60.7])\n",
        "\n",
        "mae=np.mean(np.abs(y_actual - y_pred))\n",
        "mse=np.mean((y_actual - y_pred)**2)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZJLSgkaJe6a",
        "outputId": "c5c9b5cb-ab5a-4faa-cf29-c9b5a0c2419c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.4600000000000016\n",
            "Mean Squared Error: 0.24600000000000147\n",
            "Root Mean Squared Error: 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries\n",
        "\n",
        "YActual YP red\n",
        "0 0 1 1 2 0\n",
        "0 0 1 0 2 0\n",
        "0 1 1 2 2 1\n",
        "0 2 1 0 2 2\n",
        "0 2 1 2 2 2\n",
        "Tabela 2: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "IAWmAVdhKFok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "y_actual = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n",
        "y_pred = [0, 0, 1, 2, 2, 1, 0, 2, 0, 2, 0, 0, 1, 2, 2]\n",
        "\n",
        "cm = confusion_matrix(y_actual, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "accuracy = accuracy_score(y_actual, y_pred)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "precision = precision_score(y_actual, y_pred, average=None)\n",
        "recall = recall_score(y_actual, y_pred, average=None)\n",
        "f1 = f1_score(y_actual, y_pred, average=None)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "precision_overall = precision_score(y_actual, y_pred, average='macro')\n",
        "recall_overall = recall_score(y_actual, y_pred, average='macro')\n",
        "f1_overall = f1_score(y_actual, y_pred, average='macro')\n",
        "\n",
        "print(\"\\nOverall Precision (Macro):\", precision_overall)\n",
        "print(\"Overall Recall (Macro):\", recall_overall)\n",
        "print(\"Overall F1 Score (Macro):\", f1_overall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yzaDEjLKKHa",
        "outputId": "38d54aaa-e038-430d-b504-9b45b81ad006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[2 1 2]\n",
            " [2 1 2]\n",
            " [2 1 2]]\n",
            "\n",
            "Accuracy: 0.3333333333333333\n",
            "Precision: [0.33333333 0.33333333 0.33333333]\n",
            "Recall: [0.4 0.2 0.4]\n",
            "F1 Score: [0.36363636 0.25       0.36363636]\n",
            "\n",
            "Overall Precision (Macro): 0.3333333333333333\n",
            "Overall Recall (Macro): 0.3333333333333333\n",
            "Overall F1 Score (Macro): 0.32575757575757575\n"
          ]
        }
      ]
    }
  ]
}